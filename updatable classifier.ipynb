{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sklearn.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.data\n",
    "y=df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler(feature_range=[0,1])\n",
    "scale.fit(X)\n",
    "X=scale.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(X, y, train_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47222222 0.08333333 0.6779661  0.58333333 2.        ]\n",
      " [0.02777778 0.41666667 0.05084746 0.04166667 0.        ]\n",
      " [0.36111111 0.41666667 0.59322034 0.58333333 1.        ]\n",
      " [0.16666667 0.66666667 0.06779661 0.         0.        ]\n",
      " [0.77777778 0.41666667 0.83050847 0.83333333 2.        ]\n",
      " [0.38888889 0.75       0.11864407 0.08333333 0.        ]\n",
      " [0.30555556 0.58333333 0.08474576 0.125      0.        ]\n",
      " [0.30555556 0.70833333 0.08474576 0.04166667 0.        ]\n",
      " [0.08333333 0.5        0.06779661 0.04166667 0.        ]\n",
      " [0.08333333 0.45833333 0.08474576 0.04166667 0.        ]\n",
      " [0.55555556 0.29166667 0.66101695 0.70833333 2.        ]\n",
      " [0.52777778 0.08333333 0.59322034 0.58333333 1.        ]\n",
      " [0.63888889 0.375      0.61016949 0.5        1.        ]\n",
      " [0.83333333 0.375      0.89830508 0.70833333 2.        ]\n",
      " [0.44444444 0.41666667 0.69491525 0.70833333 2.        ]\n",
      " [0.19444444 0.625      0.10169492 0.20833333 0.        ]\n",
      " [0.41666667 0.83333333 0.03389831 0.04166667 0.        ]\n",
      " [0.19444444 0.58333333 0.08474576 0.04166667 0.        ]\n",
      " [0.33333333 0.16666667 0.45762712 0.375      1.        ]\n",
      " [0.36111111 0.29166667 0.54237288 0.5        1.        ]\n",
      " [0.72222222 0.45833333 0.66101695 0.58333333 1.        ]\n",
      " [0.72222222 0.5        0.79661017 0.91666667 2.        ]\n",
      " [0.33333333 0.25       0.57627119 0.45833333 1.        ]\n",
      " [0.66666667 0.45833333 0.77966102 0.95833333 2.        ]\n",
      " [0.22222222 0.75       0.15254237 0.125      0.        ]\n",
      " [0.33333333 0.91666667 0.06779661 0.04166667 0.        ]\n",
      " [0.80555556 0.66666667 0.86440678 1.         2.        ]\n",
      " [0.63888889 0.41666667 0.57627119 0.54166667 1.        ]\n",
      " [0.58333333 0.29166667 0.72881356 0.75       2.        ]\n",
      " [0.52777778 0.375      0.55932203 0.5        1.        ]\n",
      " [0.55555556 0.33333333 0.69491525 0.58333333 2.        ]\n",
      " [0.30555556 0.79166667 0.05084746 0.125      0.        ]\n",
      " [0.94444444 0.33333333 0.96610169 0.79166667 2.        ]\n",
      " [0.47222222 0.08333333 0.50847458 0.375      1.        ]\n",
      " [0.36111111 0.41666667 0.52542373 0.5        1.        ]\n",
      " [0.66666667 0.45833333 0.57627119 0.54166667 1.        ]\n",
      " [0.19444444 0.66666667 0.06779661 0.04166667 0.        ]\n",
      " [0.44444444 0.41666667 0.54237288 0.58333333 1.        ]\n",
      " [0.16666667 0.20833333 0.59322034 0.66666667 2.        ]\n",
      " [0.22222222 0.54166667 0.11864407 0.16666667 0.        ]\n",
      " [0.58333333 0.5        0.72881356 0.91666667 2.        ]\n",
      " [0.19444444 0.41666667 0.10169492 0.04166667 0.        ]\n",
      " [0.13888889 0.58333333 0.10169492 0.04166667 0.        ]\n",
      " [0.58333333 0.5        0.59322034 0.58333333 1.        ]\n",
      " [0.16666667 0.45833333 0.08474576 0.         0.        ]\n",
      " [0.22222222 0.75       0.10169492 0.04166667 0.        ]\n",
      " [0.61111111 0.33333333 0.61016949 0.58333333 1.        ]\n",
      " [0.27777778 0.70833333 0.08474576 0.04166667 0.        ]\n",
      " [0.61111111 0.5        0.69491525 0.79166667 2.        ]\n",
      " [0.19444444 0.625      0.05084746 0.08333333 0.        ]\n",
      " [0.41666667 0.29166667 0.69491525 0.75       2.        ]\n",
      " [0.38888889 0.33333333 0.52542373 0.5        1.        ]\n",
      " [0.22222222 0.70833333 0.08474576 0.125      0.        ]\n",
      " [0.30555556 0.41666667 0.59322034 0.58333333 1.        ]\n",
      " [0.41666667 0.29166667 0.52542373 0.375      1.        ]\n",
      " [0.19444444 0.         0.42372881 0.375      1.        ]\n",
      " [0.25       0.875      0.08474576 0.         0.        ]\n",
      " [0.5        0.33333333 0.50847458 0.5        1.        ]\n",
      " [0.47222222 0.29166667 0.69491525 0.625      1.        ]\n",
      " [0.66666667 0.54166667 0.79661017 0.83333333 2.        ]\n",
      " [0.47222222 0.375      0.59322034 0.58333333 1.        ]\n",
      " [0.13888889 0.41666667 0.06779661 0.         0.        ]\n",
      " [0.66666667 0.41666667 0.6779661  0.66666667 1.        ]\n",
      " [0.41666667 0.29166667 0.49152542 0.45833333 1.        ]\n",
      " [0.58333333 0.33333333 0.77966102 0.83333333 2.        ]\n",
      " [0.38888889 0.20833333 0.6779661  0.79166667 2.        ]\n",
      " [0.11111111 0.5        0.10169492 0.04166667 0.        ]\n",
      " [0.05555556 0.125      0.05084746 0.08333333 0.        ]\n",
      " [0.66666667 0.54166667 0.79661017 1.         2.        ]\n",
      " [0.94444444 0.75       0.96610169 0.875      2.        ]\n",
      " [0.19444444 0.58333333 0.10169492 0.125      0.        ]\n",
      " [0.80555556 0.5        0.84745763 0.70833333 2.        ]\n",
      " [0.13888889 0.45833333 0.10169492 0.04166667 0.        ]\n",
      " [0.72222222 0.45833333 0.74576271 0.83333333 2.        ]\n",
      " [0.13888889 0.41666667 0.06779661 0.08333333 0.        ]\n",
      " [0.02777778 0.5        0.05084746 0.04166667 0.        ]\n",
      " [0.94444444 0.25       1.         0.91666667 2.        ]\n",
      " [0.5        0.375      0.62711864 0.54166667 1.        ]\n",
      " [0.44444444 0.5        0.6440678  0.70833333 1.        ]\n",
      " [0.66666667 0.41666667 0.71186441 0.91666667 2.        ]\n",
      " [0.         0.41666667 0.01694915 0.         0.        ]\n",
      " [0.91666667 0.41666667 0.94915254 0.83333333 2.        ]\n",
      " [0.19444444 0.5        0.03389831 0.04166667 0.        ]\n",
      " [0.52777778 0.33333333 0.6440678  0.70833333 2.        ]\n",
      " [0.66666667 0.45833333 0.62711864 0.58333333 1.        ]\n",
      " [0.61111111 0.41666667 0.76271186 0.70833333 2.        ]\n",
      " [0.33333333 0.625      0.05084746 0.04166667 0.        ]\n",
      " [0.55555556 0.20833333 0.6779661  0.75       2.        ]\n",
      " [0.55555556 0.54166667 0.62711864 0.625      1.        ]\n",
      " [0.5        0.25       0.77966102 0.54166667 2.        ]\n",
      " [0.16666667 0.45833333 0.08474576 0.04166667 0.        ]\n",
      " [0.55555556 0.125      0.57627119 0.5        1.        ]\n",
      " [0.38888889 0.375      0.54237288 0.5        1.        ]\n",
      " [0.55555556 0.58333333 0.77966102 0.95833333 2.        ]\n",
      " [0.41666667 0.25       0.50847458 0.45833333 1.        ]\n",
      " [1.         0.75       0.91525424 0.79166667 2.        ]\n",
      " [0.25       0.29166667 0.49152542 0.54166667 1.        ]\n",
      " [0.58333333 0.375      0.55932203 0.5        1.        ]\n",
      " [0.08333333 0.58333333 0.06779661 0.08333333 0.        ]\n",
      " [0.11111111 0.5        0.05084746 0.04166667 0.        ]\n",
      " [0.52777778 0.58333333 0.74576271 0.91666667 2.        ]\n",
      " [0.33333333 0.20833333 0.50847458 0.5        1.        ]\n",
      " [0.55555556 0.20833333 0.66101695 0.58333333 1.        ]\n",
      " [0.16666667 0.16666667 0.38983051 0.375      1.        ]\n",
      " [0.41666667 0.29166667 0.69491525 0.75       2.        ]\n",
      " [0.58333333 0.33333333 0.77966102 0.875      2.        ]\n",
      " [0.22222222 0.58333333 0.08474576 0.04166667 0.        ]\n",
      " [0.22222222 0.625      0.06779661 0.08333333 0.        ]\n",
      " [0.25       0.625      0.08474576 0.04166667 0.        ]\n",
      " [0.38888889 0.41666667 0.54237288 0.45833333 1.        ]\n",
      " [0.36111111 0.375      0.44067797 0.5        1.        ]\n",
      " [0.61111111 0.41666667 0.81355932 0.875      2.        ]\n",
      " [0.61111111 0.41666667 0.71186441 0.79166667 2.        ]\n",
      " [0.13888889 0.58333333 0.15254237 0.04166667 0.        ]\n",
      " [0.75       0.5        0.62711864 0.54166667 1.        ]\n",
      " [0.66666667 0.20833333 0.81355932 0.70833333 2.        ]\n",
      " [0.36111111 0.20833333 0.49152542 0.41666667 1.        ]\n",
      " [0.69444444 0.41666667 0.76271186 0.83333333 2.        ]\n",
      " [0.58333333 0.45833333 0.76271186 0.70833333 2.        ]\n",
      " [0.33333333 0.16666667 0.47457627 0.41666667 1.        ]\n",
      " [0.19444444 0.125      0.38983051 0.375      1.        ]\n",
      " [0.47222222 0.58333333 0.59322034 0.625      1.        ]\n",
      " [0.33333333 0.125      0.50847458 0.5        1.        ]\n",
      " [0.41666667 0.33333333 0.69491525 0.95833333 2.        ]\n",
      " [0.08333333 0.66666667 0.         0.04166667 0.        ]\n",
      " [0.94444444 0.41666667 0.86440678 0.91666667 2.        ]\n",
      " [0.38888889 0.25       0.42372881 0.375      1.        ]\n",
      " [0.22222222 0.75       0.08474576 0.08333333 0.        ]\n",
      " [0.38888889 0.33333333 0.59322034 0.5        1.        ]\n",
      " [0.16666667 0.41666667 0.06779661 0.04166667 0.        ]\n",
      " [0.38888889 1.         0.08474576 0.125      0.        ]\n",
      " [0.36111111 0.33333333 0.66101695 0.79166667 2.        ]\n",
      " [0.22222222 0.20833333 0.33898305 0.41666667 1.        ]\n",
      " [0.47222222 0.41666667 0.6440678  0.70833333 2.        ]\n",
      " [0.69444444 0.5        0.83050847 0.91666667 2.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "D=np.c_[train,labels_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('iris_train.csv',D,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stage :  1\n",
      "0.5333333333333333\n",
      "Train stage :  2\n",
      "0.8\n",
      "Train stage :  3\n",
      "0.7333333333333333\n",
      "Train stage :  4\n",
      "0.6\n",
      "Train stage :  5\n",
      "0.9333333333333333\n",
      "Train stage :  6\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "# updatable trainig starts here\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "i=1\n",
    "chunksize = 25\n",
    "for chunk in pd.read_csv('iris_train.csv', header=None, chunksize=chunksize):\n",
    "    train_sub = chunk\n",
    "    y = train_sub[4]\n",
    "    X = train_sub.drop([4],axis=1)\n",
    "    clf = SGDClassifier()\n",
    "    clf.partial_fit(X, y, classes=np.unique(y))\n",
    "    pred = clf.predict(test)\n",
    "    print('Train stage : ',i)\n",
    "    i =i+1\n",
    "    print(accuracy_score(pred, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
